{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# 读取数据\n",
    "root_path = \"/workspace/med_proj\"\n",
    "file_path = f\"{root_path}/data/数据汇总.csv\"\n",
    "data = pd.read_csv(file_path, index_col=None, header=0)\n",
    "# data = pd.read_excel(file_path)\n",
    "\n",
    "id2cluster = pd.read_csv(f\"{root_path}/data/48h/result.csv\", index_col=None, header=0)\n",
    "with open(f\"{root_path}/results/dataprocess/48h/name_id_mapping.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    name2id = json.load(f)\n",
    "id2name = {v: k for k, v in name2id.items()}\n",
    "\n",
    "name2cluster = {}\n",
    "for index, row in id2cluster.iterrows():\n",
    "    name2cluster[id2name[row['ID']]] = row['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', '白细胞', 'CRP', 'TNF', 'PTC', 'il6', 'il10', '性别', '年龄', 'SOFA',\n",
       "       'APACHE', 'prognosis', '机械通气', '住院时长', '是否二感', '慢性病个数', '入院感染部位',\n",
       "       '新感部位', 'BMI', '血红蛋白', '血小板', '总胆', '间胆', '白蛋白', 'AST', 'ALT', '肌酐',\n",
       "       'CRRT', '深静脉置管', '入量', '出量', '血管活性药物', '慢性心脏疾病', '慢性肝脏疾病', '慢性肺疾病',\n",
       "       '慢性肾脏疾病', '合并症', 'cluster', '感染部位拼接', '入量-出量', '高血压', '糖尿病', '肿瘤'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "with open(f\"{root_path}/results/anova/48h/name2cluster.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for name, cluster in name2cluster.items():\n",
    "        f.write(f\"{name}, {cluster}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "入院感染部位\n",
       "0    274\n",
       "1     39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"/workspace/med_proj\"\n",
    "file_path = f\"{root_path}/data/数据汇总.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data[\"入院感染部位\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', '白细胞', 'CRP', 'TNF', 'PTC', 'il6', 'il10', '性别', '年龄', 'SOFA',\n",
       "       'APACHE', 'prognosis', '机械通气', '住院时长', '是否二感', '慢性病个数', '入院感染部位',\n",
       "       '新感部位', 'BMI', '血红蛋白', '血小板', '总胆', '间胆', '白蛋白', 'AST', 'ALT', '肌酐',\n",
       "       'CRRT', '深静脉置管', '入量', '出量', '血管活性药物', '慢性心脏疾病', '慢性肝脏疾病', '慢性肺疾病',\n",
       "       '慢性肾脏疾病', '合并症', 'cluster', '感染部位拼接', '入量-出量', '高血压', '糖尿病', '肿瘤'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'int' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m入量-出量\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m入量\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m出量\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m慢性病个数\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m慢性病个数\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m---> 15\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m感染部位拼接\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m感染部位拼接\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m血液\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m入院感染部位\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m入院感染部位\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m血液\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m新感部位\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m新感部位\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m血液\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m入量-出量\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m入量\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m出量\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m慢性病个数\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m慢性病个数\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m---> 15\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m感染部位拼接\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m感染部位拼接\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m血液\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     16\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m入院感染部位\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m入院感染部位\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m血液\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m新感部位\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m新感部位\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m血液\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'int' is not iterable"
     ]
    }
   ],
   "source": [
    "df_filtered = data[data['name'].isin(name2id.keys())]\n",
    "\n",
    "# 将 name2id 中的对应ID添加到新列中\n",
    "df_filtered['cluster'] = df_filtered['name'].map(name2cluster)\n",
    "df_filtered.rename(columns={'姓名': 'name'}, inplace=True)\n",
    "df_filtered['性别'] = df_filtered['性别'].replace({'男': 1, '女': 0})\n",
    "# df_filtered['转归'] = df_filtered['转归'].replace({'存活': 0,'死亡': 1, '好转':0, \"未愈\": 1, \"其他\":0})\n",
    "df_filtered['机械通气'] = df_filtered['机械通气'].replace({'无': 0, '有': 1})\n",
    "df_filtered['是否二感'] = df_filtered['是否二感'].replace({'否': 0, '是': 1, '疑似': 0})\n",
    "df_filtered['感染部位拼接'] = df_filtered['入院感染部位'] + df_filtered['新感部位']\n",
    "df_filtered['入量-出量'] = df_filtered['入量'] - df_filtered['出量']\n",
    "\n",
    "df_filtered['慢性病个数'] = df_filtered['慢性病个数'].replace({0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1})\n",
    "\n",
    "df_filtered['感染部位拼接'] = df_filtered['感染部位拼接'].apply(lambda x: 1 if '血液' in x else 0)\n",
    "# df_filtered['入院感染部位'] = df_filtered['入院感染部位'].apply(lambda x: 1 if '血液' in x else 0)\n",
    "df_filtered['新感部位'] = df_filtered['新感部位'].apply(lambda x: 1 if '血液' in x else 0)\n",
    "\n",
    "df_filtered['CRRT'] = df_filtered['CRRT'].replace({'无': 0, '是': 1})\n",
    "df_filtered['深静脉置管'] = df_filtered['深静脉置管'].replace({'无': 0, '是': 1})\n",
    "df_filtered['血管活性药物'] = df_filtered['血管活性药物'].replace({'无': 0, '是': 1})\n",
    "\n",
    "df_filtered['慢性心脏疾病'] = df_filtered['慢性心脏疾病'].apply(lambda x: 1 if '心力衰竭' in x else 0)\n",
    "df_filtered['慢性肝脏疾病'] = df_filtered['慢性肝脏疾病'].apply(lambda x: 0 if '无' in x else 1)\n",
    "df_filtered['慢性肺疾病'] = df_filtered['慢性肺疾病'].apply(lambda x: 1 if '慢阻肺' in x else 0)\n",
    "df_filtered['慢性肾脏疾病'] = df_filtered['慢性肾脏疾病'].apply(lambda x: 0 if '无' in x else 1)\n",
    "\n",
    "\n",
    "df_filtered['高血压'] = df_filtered['合并症'].apply(lambda x: 1 if '高血压' in x else 0)\n",
    "df_filtered['糖尿病'] = df_filtered['合并症'].apply(lambda x: 1 if '糖尿病' in x else 0)\n",
    "df_filtered['肿瘤'] = df_filtered['合并症'].apply(lambda x: 1 if '肿瘤' in x else 0)\n",
    "\n",
    "df_filtered['合并症'] = df_filtered['合并症'].apply(lambda x: 1 if '无' in x else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_filtered.to_csv(f'{root_path}/results/anova/48h/cluster_feature_adjust.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/workspace/med_proj\"\n",
    "file_path = f\"{root_path}/data/数据汇总.csv\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', '白细胞', 'CRP', 'TNF', 'PTC', 'il6', 'il10', '性别', '年龄', 'SOFA',\n",
       "       'APACHE', 'prognosis', '机械通气', '住院时长', '是否二感', '慢性病个数', '入院感染部位',\n",
       "       '新感部位', 'BMI', '血红蛋白', '血小板', '总胆', '间胆', '白蛋白', 'AST', 'ALT', '肌酐',\n",
       "       'CRRT', '深静脉置管', '入量', '出量', '血管活性药物', '慢性心脏疾病', '慢性肝脏疾病', '慢性肺疾病',\n",
       "       '慢性肾脏疾病', '合并症', 'cluster', '感染部位拼接', '入量-出量', '高血压', '糖尿病', '肿瘤'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出 OR 值以及置信区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming df_filtered is your DataFrame\n",
    "data = data\n",
    "\n",
    "# The column to compare against all other columns\n",
    "reference_column = 'prognosis'\n",
    "\n",
    "# Extracting columns for Logistic Regression, excluding 'name', 'cluster' and '转归' itself\n",
    "logistic_columns = data.columns.drop(['name', 'cluster', reference_column])\n",
    "\n",
    "# Dictionary to hold Logistic Regression results\n",
    "logistic_results = {}\n",
    "\n",
    "# Function to calculate the odds ratio, 95% confidence intervals, and p-values\n",
    "def calculate_odds_ratios(result):\n",
    "    params = result.params\n",
    "    p_values = result.pvalues  # Get the p-values\n",
    "    conf = result.conf_int()\n",
    "    conf['OR'] = np.exp(params)  # Calculating the odds ratio\n",
    "    conf.columns = ['2.5%', '97.5%', 'OR']  # Renaming columns\n",
    "    # Applying exp() to 95% confidence intervals\n",
    "    conf[['2.5%', '97.5%']] = np.exp(conf[['2.5%', '97.5%']])\n",
    "    # Adding p-values\n",
    "    conf['P-value'] = p_values\n",
    "    return conf\n",
    "\n",
    "# Performing Logistic Regression for each column and storing the results\n",
    "for column in logistic_columns:\n",
    "    # Ensure the independent variable is numeric and does not contain missing values\n",
    "    X = sm.add_constant(data[column].astype(float))  # Add constant for intercept\n",
    "    \n",
    "    # Define the dependent variable (binary)\n",
    "    y = data[reference_column].astype(int)  # Ensure the dependent variable is binary\n",
    "    \n",
    "    # Fit the Logistic Regression model\n",
    "    logit_model = sm.Logit(y, X).fit(disp=0)\n",
    "    \n",
    "    # Calculate OR, confidence intervals, and p-values\n",
    "    or_ci = calculate_odds_ratios(logit_model)\n",
    "    \n",
    "    # Storing OR, CI, and p-values for each feature\n",
    "    logistic_results[column] = or_ci.loc[column]\n",
    "\n",
    "# Convert Logistic Regression results to a DataFrame\n",
    "logistic_df = pd.DataFrame(logistic_results).T\n",
    "\n",
    "# Define root_path if not defined\n",
    "\n",
    "# Saving the results to CSV files\n",
    "os.makedirs(f\"{root_path}/results/logistic/48h\", exist_ok=True)  # Create directory if not exists\n",
    "logistic_df.to_csv(f'{root_path}/results/logistic/48h/logistic_vs_zhuan_gui.csv', encoding=\"utf-8-sig\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用方差分析得到结结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import numpy as np\n",
    "\n",
    "data = df_filtered\n",
    "# Extracting columns for ANOVA, excluding 'name' and 'cluster' columns\n",
    "anova_columns = data.columns.drop(['name', 'cluster'])\n",
    "\n",
    "# Dictionary to hold ANOVA results\n",
    "anova_results = {}\n",
    "\n",
    "# Performing ANOVA for each column and storing the results\n",
    "for column in anova_columns:\n",
    "    groups = data.groupby('cluster')[column].apply(list)\n",
    "    f_val, p_val = f_oneway(*groups)\n",
    "    anova_results[column] = {'F-value': f_val, 'p-value': p_val}\n",
    "\n",
    "# Convert ANOVA results to a DataFrame\n",
    "anova_df = pd.DataFrame(anova_results).T\n",
    "\n",
    "# Calculating mean values for each column per cluster\n",
    "mean_values = data.groupby('cluster')[anova_columns].mean()\n",
    "\n",
    "# Calculating median values for each column per cluster\n",
    "median_values = data.groupby('cluster')[anova_columns].median()\n",
    "\n",
    "std_values = data.groupby('cluster')[anova_columns].std()\n",
    "\n",
    "# Calculating count of each column per cluster\n",
    "group_counts = data.groupby('cluster').size().reset_index(name='count')\n",
    "\n",
    "q1 = data.groupby('cluster')[anova_columns].quantile(0.25)\n",
    "q3 = data.groupby('cluster')[anova_columns].quantile(0.75)\n",
    "iqr_values = q3 - q1\n",
    "\n",
    "anova_df.to_csv(f'{root_path}/results/anova/48h/anova.csv', encoding=\"utf-8-sig\")\n",
    "mean_values.to_csv(f'{root_path}/results/anova/48h/mean_values.csv', encoding=\"utf-8-sig\")\n",
    "median_values.to_csv(f'{root_path}/results/anova/48h/median_values.csv', encoding=\"utf-8-sig\")\n",
    "std_values.to_csv(f'{root_path}/results/anova/48h/std_values.csv', encoding='utf-8-sig')\n",
    "group_counts.to_csv(f'{root_path}/results/anova/48h/group_counts.csv', encoding=\"utf-8-sig\")\n",
    "q1.to_csv(f'{root_path}/results/anova/48h/q1_values.csv', encoding='utf-8-sig')  # Export Q1\n",
    "q3.to_csv(f'{root_path}/results/anova/48h/q3_values.csv', encoding='utf-8-sig')\n",
    "iqr_values.to_csv(f'{root_path}/results/anova/48h/iqr_values.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 比较其中一组和其他三组的差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "\n",
    "# 假设 df_filtered 是你的数据框\n",
    "data = df_filtered\n",
    "\n",
    "# 初始化结果存储字典\n",
    "anova_results_by_cluster = {}\n",
    "\n",
    "# 需要比较的 cluster 列表\n",
    "clusters_to_compare = [1, 2, 3]\n",
    "\n",
    "# 遍历除了'name'和'cluster'外的所有列\n",
    "for column in data.columns.drop(['name', 'cluster']):\n",
    "    # 存储当前列的比较结果\n",
    "    column_results = {}\n",
    "    \n",
    "    # 对每个需要比较的 cluster 执行 ANOVA\n",
    "    for compare_cluster in clusters_to_compare:\n",
    "        # 提取 cluster = 4 和当前比较 cluster 的数据\n",
    "        group1 = data[data['cluster'] == 4][column]\n",
    "        group2 = data[data['cluster'] == compare_cluster][column]\n",
    "\n",
    "        # 执行 ANOVA\n",
    "        f_val, p_val = f_oneway(group1, group2)\n",
    "        column_results[f'cluster_4_vs_{compare_cluster}'] = {'F-value': f_val, 'p-value': p_val}\n",
    "    \n",
    "    # 将当前列的结果存入总字典\n",
    "    anova_results_by_cluster[column] = column_results\n",
    "\n",
    "# 将结果转换为更方便阅读的形式\n",
    "anova_df = pd.DataFrame.from_dict({(i, j): anova_results_by_cluster[i][j] \n",
    "                                   for i in anova_results_by_cluster.keys() \n",
    "                                   for j in anova_results_by_cluster[i].keys()},\n",
    "                                  orient='index')\n",
    "\n",
    "# 可以将结果保存为 CSV 文件\n",
    "anova_df.to_csv(f'{root_path}/results/anova/48h/cluster_4_comparisons.csv', encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 两两之间的差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# 假设 df_filtered 是你的数据框\n",
    "data = df_filtered\n",
    "\n",
    "# 初始化结果存储字典\n",
    "anova_results_by_cluster = {}\n",
    "\n",
    "# 获取所有 unique 的 cluster 值\n",
    "clusters = data['cluster'].unique()\n",
    "\n",
    "# 遍历除了 'name' 和 'cluster' 外的所有列\n",
    "for column in data.columns.drop(['name', 'cluster']):\n",
    "    # 存储当前列的比较结果\n",
    "    column_results = {}\n",
    "    \n",
    "    # 对每个可能的 cluster 组合执行 ANOVA\n",
    "    for (cluster1, cluster2) in itertools.combinations(clusters, 2):\n",
    "        # 提取 cluster1 和 cluster2 的数据\n",
    "        group1 = data[data['cluster'] == cluster1][column]\n",
    "        group2 = data[data['cluster'] == cluster2][column]\n",
    "\n",
    "        # 执行 ANOVA\n",
    "        f_val, p_val = f_oneway(group1, group2)\n",
    "        column_results[f'cluster_{cluster1}_vs_{cluster2}'] = {'F-value': f_val, 'p-value': p_val}\n",
    "    \n",
    "    # 将当前列的结果存入总字典\n",
    "    anova_results_by_cluster[column] = column_results\n",
    "\n",
    "# 将结果转换为更方便阅读的形式\n",
    "anova_df = pd.DataFrame.from_dict({(i, j): anova_results_by_cluster[i][j] \n",
    "                                   for i in anova_results_by_cluster.keys() \n",
    "                                   for j in anova_results_by_cluster[i].keys()},\n",
    "                                  orient='index')\n",
    "\n",
    "# 可以将结果保存为 CSV 文件\n",
    "anova_df.to_csv(f'{root_path}/results/anova/48h/all_clusters_comparisons.csv', encoding=\"utf-8-sig\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
