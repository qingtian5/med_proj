{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_958696/1834230997.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data = data.replace('\\\\', np.nan)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "root_path = \"/workspace/med_proj\"\n",
    "# 读取数据\n",
    "file_path = f'{root_path}/data/体温.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 数据预处理，删除无用列，选择是否删除第四天的数据，删除空行，重命名列名，添加ID列\n",
    "data = data.iloc[:, :-2]\n",
    "\n",
    "time_during = \"48h\"\n",
    "assert time_during in [\"48h\", \"72h\", \"96h\"]\n",
    "\n",
    "output_dir = f'{root_path}/results/dataprocess/{time_during}'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if time_during == \"48h\":\n",
    "    fourth_day_columns = [col for col in data.columns if '第四天' in col or '第三天' in col]\n",
    "elif time_during == \"72h\":\n",
    "    fourth_day_columns = [col for col in data.columns if '第四天' in col]\n",
    "else:\n",
    "    fourth_day_columns = []\n",
    "    \n",
    "data = data.drop(columns=fourth_day_columns)\n",
    "data = data.replace('\\\\', np.nan)\n",
    "data = data.dropna(thresh=data.shape[1] - 3)\n",
    "data = data.rename(columns={'Unnamed: 0': 'Name'})\n",
    "data['ID'] = range(1, len(data) + 1)\n",
    "\n",
    "# 保存 ID 映射表\n",
    "name_id_mapping = name_id_mapping = dict(zip(data['Name'], data['ID']))\n",
    "if time_during == \"48h\":\n",
    "    name_id_mapping['曹玉儿'] = 59\n",
    "name_id_mapping = dict(sorted(name_id_mapping.items(), key=lambda item: item[1]))\n",
    "\n",
    "\n",
    "json_file_path = f'{output_dir}/name_id_mapping.json'\n",
    "with open(json_file_path, 'w') as file:\n",
    "    json.dump(name_id_mapping, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "output_excel_path = f'{output_dir}/temperature_v1.xlsx'\n",
    "data.to_excel(output_excel_path, index=False)\n",
    "\n",
    "# 多重差补法填充缺失值\n",
    "new_data = data.drop(columns=['Name', \"ID\"])\n",
    "imputer = IterativeImputer()\n",
    "imputed_data = imputer.fit_transform(new_data)\n",
    "imputed_df_sklearn = pd.DataFrame(imputed_data, columns=new_data.columns)\n",
    "\n",
    "# 保存填充后的数据\n",
    "output_imputed_df_path = f'{output_dir}/temperature_v2.xlsx'\n",
    "imputed_df_sklearn.to_excel(output_imputed_df_path, index=False)\n",
    "\n",
    "\n",
    "# 讲数据转化为长格式\n",
    "data = imputed_df_sklearn.reset_index().rename(columns={'index': 'ID'})\n",
    "data[\"ID\"] = data[\"ID\"]+1\n",
    "melted_data = pd.melt(data, id_vars=['ID'], var_name='Time', value_name='Temperature')\n",
    "time_mapping = {time: idx for idx, time in enumerate(melted_data['Time'].unique(), start=1)}\n",
    "melted_data['Time'] = melted_data['Time'].map(time_mapping)\n",
    "melted_data_sorted = melted_data.sort_values(by=['ID', 'Time'])\n",
    "\n",
    "output_long_data_path = f'{output_dir}/temperature_v3.xlsx'\n",
    "melted_data_sorted.to_excel(output_long_data_path, index=False)\n",
    "\n",
    "if time_during == \"48h\":\n",
    "    new_columns = ['t.' + str(i) for i in range(1, 13)]\n",
    "elif time_during == \"72h\":\n",
    "    new_columns = ['t.' + str(i) for i in range(1, 19)]\n",
    "else:\n",
    "    new_columns = ['t.' + str(i) for i in range(1, 25)]\n",
    "\n",
    "imputed_df_sklearn.columns = new_columns\n",
    "\n",
    "imputed_df_sklearn.to_excel(f\"{output_dir}/wide_data.xlsx\", index=False)\n",
    "imputed_df_sklearn.to_csv(f\"{output_dir}/wide_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.0 34.3 7.700000000000003\n"
     ]
    }
   ],
   "source": [
    "df = imputed_df_sklearn\n",
    "print(df.max().max(), df.min().min(), df.max().max() - df.min().min())\n",
    "df_normalized = (df - df.min().min()) / (df.max().max() - df.min().min()) * 100   # -34.2/7.799999999999997\n",
    "df_normalized.to_csv(f\"{output_dir}/wide_data_norm.csv\", index=False)\n",
    "\n",
    "# 添加 ID 列\n",
    "df_normalized.insert(0, 'ID', range(1, 1 + len(df_normalized)))\n",
    "df_normalized.to_csv(f\"{output_dir}/wide_data_norm_id.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 48h 的结果：42.0 34.3 7.700000000000003\n",
    "\n",
    "# 使用 72h 的结果：42.0 34.2 7.799999999999997\n",
    "\n",
    "# 使用 96h 的结果：40.8 34.3 6.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
